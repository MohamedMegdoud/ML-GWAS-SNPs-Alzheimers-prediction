{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fda0392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec6cdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final class distribution:\n",
      "Counter({2: 363, 1: 363, 0: 363})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"adni_data_cleaned_with_just_dx_and_snp.csv\")\n",
    "\n",
    "# Separate features (SNPs) and target (DX)\n",
    "X = df.drop(columns=[\"DX\"])\n",
    "y = df[\"DX\"]\n",
    "\n",
    "# Define the desired class counts\n",
    "desired_counts = {0: 363, 1: 363, 2: 363}\n",
    "\n",
    "# Apply SMOTE with the desired sampling strategy\n",
    "smote = SMOTE(sampling_strategy=desired_counts, random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# Round the synthetic samples to ensure valid SNP values (0, 1, 2)\n",
    "X_res = np.round(X_res).astype(int)\n",
    "\n",
    "# Reconstruct the balanced DataFrame\n",
    "balanced_df = pd.DataFrame(X_res, columns=X.columns)\n",
    "balanced_df[\"DX\"] = y_res\n",
    "\n",
    "# Shuffle the final dataset\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save to CSV\n",
    "balanced_df.to_csv(\"adni_data_balanced.csv\", index=False)\n",
    "\n",
    "# Print the final class distribution\n",
    "print(\"Final class distribution:\")\n",
    "print(Counter(balanced_df[\"DX\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdde3b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts of DX in the balanced dataset:\n",
      "DX\n",
      "2    363\n",
      "1    363\n",
      "0    363\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#value counts\n",
    "print(\"Value counts of DX in the balanced dataset:\")\n",
    "print(balanced_df[\"DX\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3367296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the balanced dataset:\n",
      "(1089, 29) (1089,)\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into features and target\n",
    "X = balanced_df.drop(columns=[\"DX\"])\n",
    "y = balanced_df[\"DX\"]\n",
    "# Print the shape of the balanced dataset\n",
    "print(\"Shape of the balanced dataset:\")\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1afb2b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "DX\n",
      "1    363\n",
      "0    214\n",
      "2    180\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final class distribution after SMOTE:\n",
      "DX\n",
      "0    363\n",
      "2    363\n",
      "1    363\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training Logistic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.001}\n",
      "Accuracy: 0.4174\n",
      "F1 Score (macro): 0.4163\n",
      "ROC AUC: 0.6142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.39      0.40        72\n",
      "           1       0.43      0.48      0.45        73\n",
      "           2       0.42      0.38      0.40        73\n",
      "\n",
      "    accuracy                           0.42       218\n",
      "   macro avg       0.42      0.42      0.42       218\n",
      "weighted avg       0.42      0.42      0.42       218\n",
      "\n",
      "\n",
      "Training RandomForest...\n",
      "Best params: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuracy: 0.6514\n",
      "F1 Score (macro): 0.6509\n",
      "ROC AUC: 0.8381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.69      0.65        72\n",
      "           1       0.55      0.51      0.53        73\n",
      "           2       0.80      0.75      0.77        73\n",
      "\n",
      "    accuracy                           0.65       218\n",
      "   macro avg       0.65      0.65      0.65       218\n",
      "weighted avg       0.65      0.65      0.65       218\n",
      "\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200}\n",
      "Accuracy: 0.6514\n",
      "F1 Score (macro): 0.6535\n",
      "ROC AUC: 0.8026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65        72\n",
      "           1       0.56      0.62      0.59        73\n",
      "           2       0.76      0.68      0.72        73\n",
      "\n",
      "    accuracy                           0.65       218\n",
      "   macro avg       0.66      0.65      0.65       218\n",
      "weighted avg       0.66      0.65      0.65       218\n",
      "\n",
      "\n",
      "Training SVM...\n",
      "Best params: {'C': 10, 'kernel': 'rbf'}\n",
      "Accuracy: 0.6239\n",
      "F1 Score (macro): 0.6201\n",
      "ROC AUC: 0.8239\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.65      0.63        72\n",
      "           1       0.61      0.49      0.55        73\n",
      "           2       0.65      0.73      0.69        73\n",
      "\n",
      "    accuracy                           0.62       218\n",
      "   macro avg       0.62      0.62      0.62       218\n",
      "weighted avg       0.62      0.62      0.62       218\n",
      "\n",
      "\n",
      "Feature Importance for RandomForest:\n",
      "rs4255357_G     0.044667\n",
      "rs2718058_A     0.044410\n",
      "rs9381563_T     0.044244\n",
      "rs8049439_T     0.044104\n",
      "rs2456930_G     0.042922\n",
      "rs1923775_T     0.042852\n",
      "rs450674_T      0.042540\n",
      "rs11771145_G    0.042373\n",
      "rs5167_T        0.041817\n",
      "rs543844_A      0.041745\n",
      "dtype: float64\n",
      "\n",
      "Feature Importance for XGBoost:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:36:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs10012882_T    0.053934\n",
      "rs29745_A       0.044828\n",
      "rs440277_G      0.041725\n",
      "rs6882046_A     0.040157\n",
      "rs8106922_A     0.040022\n",
      "rs1448284_T     0.038345\n",
      "rs1923775_T     0.038343\n",
      "rs2718058_A     0.038026\n",
      "rs9832461_A     0.037723\n",
      "rs9381563_T     0.037115\n",
      "dtype: float32\n",
      "\n",
      "Model Comparison:\n",
      "              accuracy  f1_macro   roc_auc\n",
      "Logistic      0.417431  0.416346  0.614244\n",
      "RandomForest  0.651376  0.650864  0.838064\n",
      "XGBoost       0.651376  0.653482    0.8026\n",
      "SVM           0.623853  0.620114  0.823883\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "# import shap\n",
    "\n",
    "# Load original dataset\n",
    "df = pd.read_csv(\"adni_data_cleaned_with_just_dx_and_snp.csv\")\n",
    "\n",
    "# Check original class distribution\n",
    "print(\"Original class distribution:\")\n",
    "print(df[\"DX\"].value_counts())\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[\"DX\"])\n",
    "y = df[\"DX\"]\n",
    "\n",
    "# Apply SMOTE to balance classes\n",
    "smote = SMOTE(sampling_strategy={0: 363, 1: 363, 2: 363}, random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# Round synthetic samples to valid SNP values (0, 1, 2)\n",
    "X_res = np.round(X_res).astype(int)\n",
    "\n",
    "# Create balanced DataFrame\n",
    "balanced_df = pd.DataFrame(X_res, columns=X.columns)\n",
    "balanced_df[\"DX\"] = y_res\n",
    "\n",
    "# Final class distribution check\n",
    "print(\"\\nFinal class distribution after SMOTE:\")\n",
    "print(balanced_df[\"DX\"].value_counts())\n",
    "\n",
    "# Split into features and target as specified\n",
    "X = balanced_df.drop(columns=[\"DX\"])\n",
    "y = balanced_df[\"DX\"]\n",
    "\n",
    "# Stratified train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Define models with hyperparameter grids\n",
    "models = {\n",
    "    \"Logistic\": {\n",
    "        \"model\": LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000),\n",
    "        \"params\": {\"C\": np.logspace(-4, 4, 9)}\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [None, 10, 20],\n",
    "            \"min_samples_split\": [2, 5]\n",
    "        }\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.01, 0.1],\n",
    "            \"max_depth\": [3, 6]\n",
    "        }\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"model\": SVC(probability=True, random_state=42),\n",
    "        \"params\": {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"kernel\": ['rbf', 'linear']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "\n",
    "for name, config in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Grid search with cross-validation\n",
    "    grid = GridSearchCV(\n",
    "        config[\"model\"], \n",
    "        config[\"params\"],\n",
    "        cv=StratifiedKFold(5),\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Best model predictions\n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)\n",
    "    \n",
    "    # Get classification report as dict\n",
    "    report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "    # Handle both possible keys for weighted average\n",
    "    weighted_key = 'weighted_avg' if 'weighted_avg' in report_dict else 'weighted avg'\n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        \"best_params\": grid.best_params_,\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"f1_macro\": report_dict[weighted_key]['f1-score'],\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "    }\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Best params: {grid.best_params_}\")\n",
    "    print(f\"Accuracy: {results[name]['accuracy']:.4f}\")\n",
    "    print(f\"F1 Score (macro): {results[name]['f1_macro']:.4f}\")\n",
    "    print(f\"ROC AUC: {results[name]['roc_auc']:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance analysis for tree-based models\n",
    "tree_models = [\"RandomForest\", \"XGBoost\"]\n",
    "\n",
    "for model_name in tree_models:\n",
    "    if model_name in results:\n",
    "        print(f\"\\nFeature Importance for {model_name}:\")\n",
    "        model = models[model_name][\"model\"].set_params(**results[model_name][\"best_params\"])\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Get feature importances\n",
    "        importances = model.feature_importances_\n",
    "        feat_imp = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
    "        print(feat_imp.head(10))\n",
    "        \n",
    "        # SHAP values for XGBoost\n",
    "        # if model_name == \"XGBoost\":\n",
    "        #     explainer = shap.Explainer(model)\n",
    "        #     shap_values = explainer(X_train)\n",
    "        #     shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
    "\n",
    "# Compare all models\n",
    "print(\"\\nModel Comparison:\")\n",
    "comparison_df = pd.DataFrame(results).T\n",
    "print(comparison_df[[\"accuracy\", \"f1_macro\", \"roc_auc\"]])\n",
    "\n",
    "# Save balanced dataset\n",
    "balanced_df.to_csv(\"balanced_adni_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a32e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"adni_data_cleaned_with_just_dx_and_snp.csv\")\n",
    "X = df.drop(columns=[\"DX\"])\n",
    "y = df[\"DX\"]\n",
    "\n",
    "# Split first to prevent leakage\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Define preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False), X.columns),\n",
    "    ('pca', PCA(n_components=0.95), X.columns)\n",
    "])\n",
    "\n",
    "# Create pipeline template\n",
    "def make_pipeline(model, smote=True):\n",
    "    steps = []\n",
    "    if smote:\n",
    "        steps.append(('smote', SMOTE(sampling_strategy={0: 363, 1: 363, 2: 363}, random_state=42)))\n",
    "    steps.extend([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('feature_selector', SelectKBest(f_classif, k=20)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    return imbpipeline(steps)\n",
    "\n",
    "# Define models with expanded hyperparameter spaces\n",
    "models = {\n",
    "    \"Logistic\": {\n",
    "        'pipeline': make_pipeline(LogisticRegression(multi_class='multinomial', solver='saga', max_iter=1000)),\n",
    "        'params': {\n",
    "            'model__C': Real(1e-5, 1e5, prior='log-uniform'),\n",
    "            'feature_selector__k': Integer(10, 30)\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"RF\": {\n",
    "        'pipeline': make_pipeline(RandomForestClassifier(random_state=42)),\n",
    "        'params': {\n",
    "            'model__n_estimators': Integer(100, 500),\n",
    "            'model__max_depth': Integer(3, 20),\n",
    "            'model__min_samples_split': Integer(2, 11),\n",
    "            'model__class_weight': Categorical(['balanced', 'balanced_subsample'])\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"XGBoost\": {\n",
    "        'pipeline': make_pipeline(XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')),\n",
    "        'params': {\n",
    "            'model__n_estimators': Integer(50, 300),\n",
    "            'model__learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
    "            'model__max_depth': Integer(3, 12),\n",
    "            'model__subsample': Real(0.6, 1.0),\n",
    "            'model__colsample_bytree': Real(0.6, 1.0)\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"LGBM\": {\n",
    "        'pipeline': make_pipeline(LGBMClassifier(random_state=42)),\n",
    "        'params': {\n",
    "            'model__n_estimators': Integer(50, 300),\n",
    "            'model__learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
    "            'model__num_leaves': Integer(10, 200),\n",
    "            'model__feature_fraction': Real(0.6, 1.0),\n",
    "            'model__bagging_fraction': Real(0.6, 1.0)\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"Stacking\": {\n",
    "        'pipeline': None,  # Will be defined after individual models are trained\n",
    "        'params': {}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Train base models with Bayesian optimization\n",
    "best_models = {}\n",
    "results = {}\n",
    "\n",
    "for name in [\"Logistic\", \"RF\", \"XGBoost\", \"LGBM\"]:\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Create and fit optimizer\n",
    "    opt = BayesSearchCV(\n",
    "        models[name]['pipeline'],\n",
    "        models[name]['params'],\n",
    "        n_iter=50,\n",
    "        cv=StratifiedKFold(5),\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    opt.fit(X_train, y_train)\n",
    "    \n",
    "    # Store results\n",
    "    best_models[name] = opt\n",
    "    y_pred = opt.predict(X_test)\n",
    "    y_proba = opt.predict_proba(X_test)\n",
    "    \n",
    "    results[name] = {\n",
    "        \"best_params\": opt.best_params_,\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"f1_macro\": classification_report(y_test, y_pred, output_dict=True)['weighted avg']['f1-score'],\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} Accuracy: {results[name]['accuracy']:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Create stacking ensemble\n",
    "estimators = [\n",
    "    ('rf', best_models['RF'].best_estimator_),\n",
    "    ('xgb', best_models['XGBoost'].best_estimator_),\n",
    "    ('lgbm', best_models['LGBM'].best_estimator_)\n",
    "]\n",
    "\n",
    "stacking = Pipeline([\n",
    "    ('smote', SMOTE(sampling_strategy={0: 363, 1: 363, 2: 363}, random_state=42)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('stack', VotingClassifier(estimators, voting='soft'))\n",
    "])\n",
    "\n",
    "stacking.fit(X_train, y_train)\n",
    "y_pred = stacking.predict(X_test)\n",
    "y_proba = stacking.predict_proba(X_test)\n",
    "\n",
    "results[\"Stacking\"] = {\n",
    "    \"best_params\": \"Ensemble of best models\",\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"f1_macro\": classification_report(y_test, y_pred, output_dict=True)['weighted avg']['f1-score'],\n",
    "    \"roc_auc\": roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "}\n",
    "\n",
    "# Feature importance analysis\n",
    "print(\"\\nTop Features:\")\n",
    "for name in [\"RF\", \"XGBoost\", \"LGBM\"]:\n",
    "    feat_imp = pd.Series(best_models[name].best_estimator_.named_steps['model'].feature_importances_, \n",
    "                        index=X.columns).sort_values(ascending=False)\n",
    "    print(f\"\\n{name} Top 10 Features:\")\n",
    "    print(feat_imp.head(10))\n",
    "\n",
    "# Compare results\n",
    "comparison_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(comparison_df[[\"accuracy\", \"f1_macro\", \"roc_auc\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
