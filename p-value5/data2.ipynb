{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e250b4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rs8077028_T', 'rs2244526_T', 'rs17022021_T', 'rs1034435_A', 'rs4760243_A']\n"
     ]
    }
   ],
   "source": [
    "# open gwas_clean_riskAllele_ids_with_beta8.txt and read each line and split it into a list\n",
    "with open('snp_with_pvalue5.txt') as f:\n",
    "    columns = []\n",
    "    for line in f:\n",
    "        # split the line into a list and append it to the columns list\n",
    "        columns.append(line.strip().split())\n",
    "# flatten the list of lists into a single list\n",
    "p_value5_id = [item for sublist in columns for item in sublist]\n",
    "# print the first 5 columns\n",
    "print(p_value5_id[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0306833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4557b22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4348/738370358.py:1: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data_with_no_filtering = pd.read_csv('../adni_full.raw', delim_whitespace=True, usecols= lambda x: not x.endswith('.'), nrows=5)\n"
     ]
    }
   ],
   "source": [
    "data_with_no_filtering = pd.read_csv('../adni_full.raw', delim_whitespace=True, usecols= lambda x: not x.endswith('.'), nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf6d3175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592538"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_with_no_filtering.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce1854be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs4255357_G is in the list\n",
      "rs2970989_T is in the list\n",
      "rs1552244_A is in the list\n",
      "rs17022021_T is in the list\n",
      "rs9832461_A is in the list\n",
      "rs17785248_A is in the list\n",
      "rs4974424_A is in the list\n",
      "rs1923775_T is in the list\n",
      "rs1448284_T is in the list\n",
      "rs10012882_T is in the list\n",
      "rs13178362_T is in the list\n",
      "rs29745_A is in the list\n",
      "rs6882046_A is in the list\n",
      "rs543844_A is in the list\n",
      "rs9381563_T is in the list\n",
      "rs2718058_A is in the list\n",
      "rs11771145_G is in the list\n",
      "rs7016182_C is in the list\n",
      "rs956225_A is in the list\n",
      "rs474951_T is in the list\n",
      "rs7155434_A is in the list\n",
      "rs10498633_G is in the list\n",
      "rs2456930_G is in the list\n",
      "rs8049439_T is in the list\n",
      "rs450674_T is in the list\n",
      "rs16973424_A is in the list\n",
      "rs440277_G is in the list\n",
      "rs8106922_A is in the list\n",
      "rs5167_T is in the list\n",
      "['rs4255357_G', 'rs2970989_T', 'rs1552244_A', 'rs17022021_T', 'rs9832461_A', 'rs17785248_A', 'rs4974424_A', 'rs1923775_T', 'rs1448284_T', 'rs10012882_T', 'rs13178362_T', 'rs29745_A', 'rs6882046_A', 'rs543844_A', 'rs9381563_T', 'rs2718058_A', 'rs11771145_G', 'rs7016182_C', 'rs956225_A', 'rs474951_T', 'rs7155434_A', 'rs10498633_G', 'rs2456930_G', 'rs8049439_T', 'rs450674_T', 'rs16973424_A', 'rs440277_G', 'rs8106922_A', 'rs5167_T']\n"
     ]
    }
   ],
   "source": [
    "id_of_pvalue5 = []\n",
    "for col in data_with_no_filtering.columns:\n",
    "    if col in p_value5_id:\n",
    "        print(col, \"is in the list\")\n",
    "        id_of_pvalue5.append(col)\n",
    "print(id_of_pvalue5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bd75278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4348/1183739696.py:8: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data_with_filtering = pd.read_csv('../adni_full.raw', delim_whitespace=True, usecols=columns_to_use)\n"
     ]
    }
   ],
   "source": [
    "# read the data again with the selected columns and first 6 columns of data and first 5 rows\n",
    "metadata_cols = ['FID', 'IID', 'PAT', 'MAT', 'SEX','PHENOTYPE']\n",
    "\n",
    "# Combine metadata columns with your filtered SNP rsIDs\n",
    "columns_to_use = metadata_cols + id_of_pvalue5\n",
    "\n",
    "# Read only those columns (first 5 + selected SNPs) and first 5 rows\n",
    "data_with_filtering = pd.read_csv('../adni_full.raw', delim_whitespace=True, usecols=columns_to_use)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cd9667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "FID             0\n",
      "IID             0\n",
      "PAT             0\n",
      "MAT             0\n",
      "SEX             0\n",
      "PHENOTYPE       0\n",
      "rs4255357_G     7\n",
      "rs2970989_T     0\n",
      "rs1552244_A     0\n",
      "rs17022021_T    0\n",
      "rs9832461_A     0\n",
      "rs17785248_A    4\n",
      "rs4974424_A     2\n",
      "rs1923775_T     0\n",
      "rs1448284_T     0\n",
      "rs10012882_T    2\n",
      "rs13178362_T    1\n",
      "rs29745_A       1\n",
      "rs6882046_A     2\n",
      "rs543844_A      0\n",
      "rs9381563_T     9\n",
      "rs2718058_A     1\n",
      "rs11771145_G    0\n",
      "rs7016182_C     0\n",
      "rs956225_A      0\n",
      "rs474951_T      1\n",
      "rs7155434_A     2\n",
      "rs10498633_G    0\n",
      "rs2456930_G     1\n",
      "rs8049439_T     0\n",
      "rs450674_T      0\n",
      "rs16973424_A    1\n",
      "rs440277_G      0\n",
      "rs8106922_A     0\n",
      "rs5167_T        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#caclulate missing values of every column\n",
    "missing_values = data_with_filtering.isnull().sum()\n",
    "# Print the missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)\n",
    "#see the minimum and median and maximum of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a92b13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4348/151881563.py:2: DtypeWarning: Columns (19,20,21,50,51,104,105,106) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  adni_merge = pd.read_csv('../ADNIMERGE_11May2025.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load ADNIMERGE\n",
    "adni_merge = pd.read_csv('../ADNIMERGE_11May2025.csv')\n",
    "\n",
    "# Keep only baseline DX information\n",
    "adni_dx = adni_merge[adni_merge['VISCODE'] == 'bl'][['RID', 'DX']]\n",
    "\n",
    "# Extract RID (subject ID) from IID (e.g., '014_S_0520' → 520)\n",
    "data_with_filtering['RID'] = data_with_filtering['IID'].str.extract(r'_(\\d+)$').astype(float).astype(int)\n",
    "\n",
    "# Merge DX info\n",
    "data_with_filtering = pd.merge(data_with_filtering, adni_dx, on='RID', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49b5673e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['FID', 'IID', 'PAT', 'MAT', 'SEX', 'PHENOTYPE', 'rs4255357_G',\n",
      "       'rs2970989_T', 'rs1552244_A', 'rs17022021_T', 'rs9832461_A',\n",
      "       'rs17785248_A', 'rs4974424_A', 'rs1923775_T', 'rs1448284_T',\n",
      "       'rs10012882_T', 'rs13178362_T', 'rs29745_A', 'rs6882046_A',\n",
      "       'rs543844_A', 'rs9381563_T', 'rs2718058_A', 'rs11771145_G',\n",
      "       'rs7016182_C', 'rs956225_A', 'rs474951_T', 'rs7155434_A',\n",
      "       'rs10498633_G', 'rs2456930_G', 'rs8049439_T', 'rs450674_T',\n",
      "       'rs16973424_A', 'rs440277_G', 'rs8106922_A', 'rs5167_T', 'RID', 'DX'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_with_filtering.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f69fd3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = ['FID', 'IID', 'PAT', 'MAT','SEX', 'PHENOTYPE', 'RID']  # Adjust the list based on your data\n",
    "\n",
    "# Drop the specified columns\n",
    "data_cleaned_with_just_dx_and_snp = data_with_filtering.drop(columns=columns_to_remove)\n",
    "#convert data_cleaned_with_just_dx_and_snp to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91e32804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in each column with its mode and except dx columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5861e592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4348/1545016660.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned_with_just_dx_and_snp[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_4348/1545016660.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned_with_just_dx_and_snp[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_4348/1545016660.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned_with_just_dx_and_snp[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_4348/1545016660.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned_with_just_dx_and_snp[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_4348/1545016660.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned_with_just_dx_and_snp[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_4348/1545016660.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned_with_just_dx_and_snp[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_4348/1545016660.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned_with_just_dx_and_snp[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_4348/1545016660.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned_with_just_dx_and_snp[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_4348/1545016660.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned_with_just_dx_and_snp[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_4348/1545016660.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned_with_just_dx_and_snp[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_4348/1545016660.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned_with_just_dx_and_snp[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_4348/1545016660.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned_with_just_dx_and_snp[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_4348/1545016660.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned_with_just_dx_and_snp[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_4348/1545016660.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned_with_just_dx_and_snp[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_4348/1545016660.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned_with_just_dx_and_snp[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_4348/1545016660.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned_with_just_dx_and_snp[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_4348/1545016660.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned_with_just_dx_and_snp[column].fillna(mode_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with mode for all columns except 'DX'\n",
    "for column in data_cleaned_with_just_dx_and_snp.columns:\n",
    "    if column != 'DX':\n",
    "        mode_value = data_cleaned_with_just_dx_and_snp[column].mode()[0]\n",
    "        data_cleaned_with_just_dx_and_snp[column].fillna(mode_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01ceabbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4348/3523527163.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data_cleaned_with_just_dx_and_snp['DX'] = data_cleaned_with_just_dx_and_snp['DX'].replace(dx_mapping)\n"
     ]
    }
   ],
   "source": [
    "# Map DX values to numerical values\n",
    "dx_mapping = {'CN': 0, 'MCI': 1, 'Dementia': 2}\n",
    "data_cleaned_with_just_dx_and_snp['DX'] = data_cleaned_with_just_dx_and_snp['DX'].replace(dx_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e473ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4144736842105263\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.17      0.22        42\n",
      "           1       0.46      0.74      0.56        72\n",
      "           2       0.21      0.08      0.12        38\n",
      "\n",
      "    accuracy                           0.41       152\n",
      "   macro avg       0.33      0.33      0.30       152\n",
      "weighted avg       0.36      0.41      0.36       152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data_cleaned_with_just_dx_and_snp.drop(columns=['DX'])\n",
    "y = data_cleaned_with_just_dx_and_snp['DX']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Fit the model to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "321b5cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Logistic Regression with Accuracy: 0.4306\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg_scores = cross_val_score(logreg, X, y, cv=5, scoring='accuracy')\n",
    "logreg_mean_accuracy = logreg_scores.mean()\n",
    "\n",
    "# Gradient Boosting\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc_scores = cross_val_score(gbc, X, y, cv=5, scoring='accuracy')\n",
    "gbc_mean_accuracy = gbc_scores.mean()\n",
    "\n",
    "# Deep Learning Model (MLPClassifier)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "mlp_accuracies = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    mlp_accuracies.append(accuracy_score(y_test, y_pred))\n",
    "mlp_mean_accuracy = sum(mlp_accuracies) / len(mlp_accuracies)\n",
    "\n",
    "# Compare and choose the best model\n",
    "best_model = max(\n",
    "    [('Logistic Regression', logreg_mean_accuracy),\n",
    "     ('Gradient Boosting', gbc_mean_accuracy),\n",
    "     ('Deep Learning', mlp_mean_accuracy)],\n",
    "    key=lambda x: x[1]\n",
    ")\n",
    "\n",
    "print(f\"Best Model: {best_model[0]} with Accuracy: {best_model[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92a9adb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Accuracy: 0.4768211920529801\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        40\n",
      "           1       0.48      1.00      0.65        72\n",
      "           2       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.48       151\n",
      "   macro avg       0.16      0.33      0.22       151\n",
      "weighted avg       0.23      0.48      0.31       151\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for Gradient Boosting\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(estimator=gbc, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_gbc = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred = best_gbc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Improved Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "413aca20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Deep Learning Model Accuracy: 0.4280\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define a new deep learning model with a more complex architecture\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "improved_mlp_accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # New architecture with more layers and neurons\n",
    "    improved_mlp = MLPClassifier(hidden_layer_sizes=(200, 100, 50), \n",
    "                                  activation='relu', \n",
    "                                  solver='adam', \n",
    "                                  max_iter=1000, \n",
    "                                  random_state=42)\n",
    "    improved_mlp.fit(X_train, y_train)\n",
    "    y_pred = improved_mlp.predict(X_test)\n",
    "    improved_mlp_accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Calculate the mean accuracy\n",
    "improved_mlp_mean_accuracy = sum(improved_mlp_accuracies) / len(improved_mlp_accuracies)\n",
    "\n",
    "print(f\"Improved Deep Learning Model Accuracy: {improved_mlp_mean_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f40fcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.4304635761589404\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.12      0.16        40\n",
      "           1       0.47      0.82      0.60        72\n",
      "           2       0.25      0.03      0.05        39\n",
      "\n",
      "    accuracy                           0.43       151\n",
      "   macro avg       0.32      0.32      0.27       151\n",
      "weighted avg       0.35      0.43      0.34       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e770cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-3.0.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Using cached nvidia_nccl_cu12-2.26.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: scipy in /home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-3.0.0-py3-none-manylinux_2_28_x86_64.whl (253.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 MB\u001b[0m \u001b[31m412.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:17\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (318.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:06\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
      "Successfully installed nvidia-nccl-cu12-2.26.5 xgboost-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "636bf3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamed-megdoud/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [13:44:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.3973509933774834\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.28      0.25        40\n",
      "           1       0.50      0.62      0.56        72\n",
      "           2       0.29      0.10      0.15        39\n",
      "\n",
      "    accuracy                           0.40       151\n",
      "   macro avg       0.34      0.33      0.32       151\n",
      "weighted avg       0.37      0.40      0.37       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier # type: ignore\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost Accuracy: {accuracy_xgb}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fafcad6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized Logistic Regression Accuracy: 0.45695364238410596\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.28      0.32        40\n",
      "           1       0.50      0.79      0.61        72\n",
      "           2       0.12      0.03      0.04        39\n",
      "\n",
      "    accuracy                           0.46       151\n",
      "   macro avg       0.34      0.36      0.33       151\n",
      "weighted avg       0.37      0.46      0.39       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the logistic regression model with L2 regularization (default)\n",
    "logreg_regularized = LogisticRegression(penalty='l2', C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "logreg_regularized.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_regularized = logreg_regularized.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_regularized = accuracy_score(y_test, y_pred_regularized)\n",
    "print(f\"Regularized Logistic Regression Accuracy: {accuracy_regularized}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_regularized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6df836c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Logistic Regression Accuracy: 0.48344370860927155\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.28      0.34        40\n",
      "           1       0.51      0.85      0.64        72\n",
      "           2       0.14      0.03      0.04        39\n",
      "\n",
      "    accuracy                           0.48       151\n",
      "   macro avg       0.37      0.38      0.34       151\n",
      "weighted avg       0.40      0.48      0.41       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the logistic regression model with L1 regularization\n",
    "logreg_lasso = LogisticRegression(penalty='l1', solver='saga', C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "logreg_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lasso = logreg_lasso.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_lasso = accuracy_score(y_test, y_pred_lasso)\n",
    "print(f\"Lasso Logistic Regression Accuracy: {accuracy_lasso}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lasso))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
